{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. listing the name of the first 10 products in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stop Pacifier Sucking without tears with Thumb...\n",
       "1      Nature's Lullabies Second Year Sticker Calendar\n",
       "2      Nature's Lullabies Second Year Sticker Calendar\n",
       "3                          Lamaze Peekaboo, I Love You\n",
       "4    SoftPlay Peek-A-Boo Where's Elmo A Children's ...\n",
       "5                            Our Baby Girl Memory Book\n",
       "6    Hunnt&reg; Falling Flowers and Birds Kids Nurs...\n",
       "7    Blessed By Pope Benedict XVI Divine Mercy Full...\n",
       "8    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "9    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['name'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. counting the number of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26579\n",
      "26493\n",
      "53072\n"
     ]
    }
   ],
   "source": [
    "print (products['sentiment'] == 1).sum()\n",
    "print (products['sentiment'] == -1).sum()\n",
    "print (products['sentiment']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Apply text cleaning on the review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. load the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'baby', u'one', u'great']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('important_words.json') as important_words_file:    \n",
    "    important_words = json.load(important_words_file)\n",
    "print important_words[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. data transformations:\n",
    "- fill n/a values in the review column with empty strings\n",
    "- Remove punctuation\n",
    "- Compute word counts (only for important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>My daughter had her 1st baby over a year ago S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "1  We wanted to get something to keep track of ou...       5          1   \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1   \n",
       "\n",
       "                                        review_clean  \n",
       "0  All of my kids have cried nonstop when I tried...  \n",
       "1  We wanted to get something to keep track of ou...  \n",
       "2  My daughter had her 1st baby over a year ago S...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "products.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. compute a count for the number of times the word occurs in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  All of my kids have cried non-stop when I trie...       5          1   \n",
       "\n",
       "                                        review_clean  baby  one  great  love  \\\n",
       "0  All of my kids have cried nonstop when I tried...     0    0      1     0   \n",
       "\n",
       "   use   ...    seems  picture  completely  wish  buying  babies  won  tub  \\\n",
       "0    0   ...        0        0           0     0       0       0    0    0   \n",
       "\n",
       "   almost  either  \n",
       "0       0       0  \n",
       "\n",
       "[1 rows x 198 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " ### 7. compute the number of product reviews that contain the word perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2955\n"
     ]
    }
   ],
   "source": [
    "products['contains_perfect'] = products['perfect'] >=1\n",
    "print products['contains_perfect'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Quiz Question. \n",
    "How many reviews contain the word perfect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Answer \n",
    "2955"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Convert data frame to multi-dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 8.  convert our data frame to a multi-dimensional array.\n",
    "The function should accept three parameters:\n",
    "- dataframe: a data frame to be converted\n",
    "- features: a list of string, containing the names of the columns that are used as features.\n",
    "- label: a string, containing the name of the single column that is used as class labels.\n",
    "\n",
    "The function should return two values:\n",
    "\n",
    "- one 2D array for features\n",
    "- one 1D array for class labels\n",
    "\n",
    "The function should do the following:\n",
    "- Prepend a new column constant to dataframe and fill it with 1's. This column takes account of the intercept term. Make sure that the constant column appears first in the data frame.\n",
    "- Prepend a string 'constant' to the list features. Make sure the string 'constant' appears first in the list.\n",
    "- Extract columns in dataframe whose names appear in the list features.\n",
    "- Convert the extracted columns into a 2D array using a function in the data frame library. If you are using Pandas, you would use as_matrix() function.\n",
    "- Extract the single column in dataframe whose name corresponds to the string label.\n",
    "- Convert the column into a 1D array.\n",
    "- Return the 2D array and the 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "    features_frame = dataframe[features]\n",
    "    feature_matrix = features_frame.as_matrix()\n",
    "    label_sarray = dataframe[label]\n",
    "    label_array = label_sarray.as_matrix()\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9. extract two arrays feature_matrix and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Quiz Question: \n",
    "How many features are there in the feature_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53072L, 194L)\n"
     ]
    }
   ],
   "source": [
    "print feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Answer:\n",
    "194"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Quiz Question: \n",
    "Assuming that the intercept is present, how does the number of features in feature_matrix relate to the number of features in the logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Estimating conditional probability with link function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 10. Compute predictions given by the link function.\n",
    "- Take two parameters: feature_matrix and coefficients.\n",
    "- First compute the dot product of feature_matrix and coefficients.\n",
    "- Then compute the link function P(y=+1|x,w).\n",
    "- Return the predictions given by the link function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "feature_matrix: N * D\n",
    "coefficients: D * 1\n",
    "predictions: N * 1\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    # YOUR CODE HERE\n",
    "    score = np.dot(feature_matrix, coefficients) # N * 1\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    # YOUR CODE HERE\n",
    "    predictions = 1.0/(1+np.exp(-score))\n",
    "    \n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Compute derivative of log likelihood with respect to a single coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 11. computes the derivative of log likelihood with respect to a single coefficient w_j\n",
    "The function should do the following:\n",
    "\n",
    "- Take two parameters errors and feature.\n",
    "- Compute the dot product of errors and feature.\n",
    "- Return the dot product. This is the derivative with respect to a single coefficient w_j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "errors: N * 1\n",
    "feature: N * 1\n",
    "derivative: 1 \n",
    "\"\"\"\n",
    "def feature_derivative(errors, feature):     \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = np.dot(np.transpose(errors), feature)\n",
    "    # Return the derivative\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 12. Write a function compute_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    # scores.shape (53072L, 1L)\n",
    "    # indicator.shape (53072L,)\n",
    "    lp = np.sum((np.transpose(np.array([indicator]))-1)*scores - np.log(1. + np.exp(-scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Taking gradient steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 13. Write a function logistic_regression to fit a logistic regression model using gradient ascent.\n",
    "The function accepts the following parameters:\n",
    "\n",
    "- feature_matrix: 2D array of features\n",
    "- sentiment: 1D array of class labels\n",
    "- initial_coefficients: 1D array containing initial values of coefficients\n",
    "- step_size: a parameter controlling the size of the gradient steps\n",
    "- max_iter: number of iterations to run gradient ascent\n",
    "- The function returns the last set of coefficients after performing gradient ascent.\n",
    "\n",
    "The function carries out the following steps:\n",
    "\n",
    "1. Initialize vector coefficients to initial_coefficients.\n",
    "1. Predict the class probability P(yi=+1|xi,w) using your predict_probability function and save it to variable predictions.\n",
    "1. Compute indicator value for (yi=+1) by comparing sentiment against +1. Save it to variable indicator.\n",
    "1. Compute the errors as difference between indicator and predictions. Save the errors to variable errors.\n",
    "1. For each j-th coefficient, compute the per-coefficient derivative by calling feature_derivative with the j-th column of feature_matrix. Then increment the j-th coefficient by (step_size*derivative).\n",
    "1. Once in a while, insert code to print out the log likelihood.\n",
    "1. Repeat steps 2-6 for max_iter times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# coefficients: D * 1\n",
    "from math import sqrt\n",
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    # lplist = []\n",
    "    for itr in xrange(max_iter):\n",
    "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
    "        # YOUR CODE HERE\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "\n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "\n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = np.transpose(np.array([indicator])) - predictions\n",
    "\n",
    "        for j in xrange(len(coefficients)): # loop over each coefficient\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j]\n",
    "            # compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            # YOUR CODE HERE\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,j])\n",
    "\n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            # YOUR CODE HERE\n",
    "            coefficients[j] += step_size*derivative\n",
    "\n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            # lplist.append(compute_log_likelihood(feature_matrix, sentiment, coefficients))\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    x= [i for i in range(len(lplist))]\n",
    "    plt.plot(x,lplist,'ro')\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 14. run the logistic regression solver\n",
    "- feature_matrix = feature_matrix extracted in #9\n",
    "- sentiment = sentiment extracted in #9\n",
    "- initial_coefficients = a 194-dimensional vector filled with zeros\n",
    "- step_size = 1e-7\n",
    "- max_iter = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "initial_coefficients = np.zeros((194,1))\n",
    "step_size = 1e-7\n",
    "max_iter = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEACAYAAABLfPrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf91c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Quiz question : \n",
    "As each iteration of gradient ascent passes, does the log likelihood increase or decrease?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Answer\n",
    "increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 15. compute class predictions\n",
    "- First compute the scores using feature_matrix and coefficients using a dot product.\n",
    "- Then apply threshold 0 on the scores to compute the class predictions. Refer to the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25126\n",
      "25126\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "feature_matrix: N * D\n",
    "coefficients: D * 1\n",
    "predictions: N * 1\n",
    "\"\"\"\n",
    "predictions = predict_probability(feature_matrix, coefficients)\n",
    "NumPositive = (predictions > 0.5).sum()\n",
    "print NumPositive\n",
    "\n",
    "score = np.dot(feature_matrix, coefficients) # N * 1\n",
    "print (score > 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 6. Quiz question: \n",
    "How many reviews were predicted to have positive sentiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Answer:\n",
    "25126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print 0 in products['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print -1 in products['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53072L,)\n",
      "(53072L,)\n"
     ]
    }
   ],
   "source": [
    "print np.transpose(predictions.flatten()).shape\n",
    "print (products['sentiment']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51275866  0.49265935  0.50602867  0.50196725  0.53290719]\n"
     ]
    }
   ],
   "source": [
    "print (np.transpose(predictions.flatten()))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_num: 39903, total_num: 53072\n",
      "0.751865390413\n"
     ]
    }
   ],
   "source": [
    "correct_num = np.sum((np.transpose(predictions.flatten())> 0.5) == np.array(products['sentiment']>0))\n",
    "total_num = len(products['sentiment'])\n",
    "print \"correct_num: {}, total_num: {}\".format(correct_num, total_num)\n",
    "accuracy = correct_num * 1./ total_num\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ..., False,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(predictions.flatten())> 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(products['sentiment']>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_num: 39903, total_num: 53072\n",
      "0.751865390413\n"
     ]
    }
   ],
   "source": [
    "correct_num = np.sum((np.transpose(score.flatten())> 0) == np.array(products['sentiment']>0))\n",
    "total_num = len(products['sentiment'])\n",
    "print \"correct_num: {}, total_num: {}\".format(correct_num, total_num)\n",
    "accuracy = correct_num * 1./ total_num\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 7. Quiz question: \n",
    "What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Answer:\n",
    "0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Which words contribute most to positive & negative sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 17.compute the \"most positive words\"\n",
    "- Treat each coefficient as a tuple, i.e. (word, coefficient_value). The intercept has no corresponding word, so throw it out.\n",
    "- Sort all the (word, coefficient_value) tuples by coefficient_value in descending order. Save the sorted list of tuples to word_coefficient_tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ten \"most positive\" words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 18. Compute the 10 most positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'great', array([ 0.06654608])),\n",
       " (u'love', array([ 0.06589076])),\n",
       " (u'easy', array([ 0.06479459])),\n",
       " (u'little', array([ 0.04543563])),\n",
       " (u'loves', array([ 0.0449764])),\n",
       " (u'well', array([ 0.030135])),\n",
       " (u'perfect', array([ 0.02973994])),\n",
       " (u'old', array([ 0.02007754])),\n",
       " (u'nice', array([ 0.01840871])),\n",
       " (u'daughter', array([ 0.0177032]))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 8. Quiz question: \n",
    "Which word is not present in the top 10 \"most positive\" words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ten \"most negative\" words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'monitor', array([-0.0244821])),\n",
       " (u'return', array([-0.02659278])),\n",
       " (u'back', array([-0.0277427])),\n",
       " (u'get', array([-0.02871155])),\n",
       " (u'disappointed', array([-0.02897898])),\n",
       " (u'even', array([-0.03005125])),\n",
       " (u'work', array([-0.03306952])),\n",
       " (u'money', array([-0.03898204])),\n",
       " (u'product', array([-0.04151103])),\n",
       " (u'would', array([-0.05386015]))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9. Quiz question: \n",
    "Which word is not present in the top 10 \"most negative\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False]\n"
     ]
    }
   ],
   "source": [
    "print np.array([1,2,3])==np.array([1,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
